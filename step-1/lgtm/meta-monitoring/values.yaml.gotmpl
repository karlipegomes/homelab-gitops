cloud:
  logs:
    enabled: false
  metrics:
    enabled: false
  traces:
    enabled: false
local:
  grafana:
    enabled: true
  logs:
    enabled: true
  metrics:
    enabled: true
  traces:
    enabled: true
  minio:
    enabled: false 
#
grafana:
  ingress:
    enabled: true
    ingressClassName: "nginx-external"
    annotations:
      cert-manager.io/cluster-issuer: letsencrypt-prod
    hosts:
      - host: monitoring.staffops.cloud
        paths:
          - path: /
            pathType: Prefix
    tls:
     - secretName: monitoring-staffops-cloud-tls
       hosts:
         - monitoring.staffops.cloud
#
dashboards:
  logs:
    enabled: true
kubeStateMetrics:
  # Scrape https://github.com/kubernetes/kube-state-metrics by default
  enabled: true
  # This endpoint is created when the helm chart from
  # https://artifacthub.io/packages/helm/prometheus-community/kube-state-metrics/
  # is used. Change this if kube-state-metrics is installed somewhere else.
  endpoint: kube-state-metrics.kube-state-metrics.svc.cluster.local:8080
# The following are configuration for the dependencies.
# These should usually not be changed.
loki:
  loki:
    auth_enabled: false
    schemaConfig:
      configs:
        - from: 2024-03-29
          store: tsdb
          object_store: s3
          schema: v13
          index:
            prefix: index_
            period: 24h
    storage:
      type: "s3"
      s3:
        insecure: true
        s3ForcePathStyle: true
      bucketNames:
        chunks: loki-chunks
        ruler: loki-ruler
    structuredConfig:
      common:
        storage:
          s3:
            access_key_id: "${rootUser}"
            endpoint: "{{ .Release.Name }}-minio.{{ .Release.Namespace }}.svc:9000"
            secret_access_key: "${rootPassword}"
      compactor:
        retention_enabled: true
        delete_request_store: s3
      limits_config:
        retention_period: 30d
  lokiCanary:
    enabled: false
  test:
    enabled: false
  monitoring:
    dashboards:
      enabled: false
    rules:
      enabled: false
    serviceMonitor:
      enabled: false
    selfMonitoring:
      enabled: false
      grafanaAgent:
        installOperator: false
    lokiCanary:
      enabled: false
  write:
    extraArgs:
    - "-config.expand-env=true"
    extraEnvFrom:
    - secretRef:
        name: "minio"
  read:
    extraArgs:
    - "-config.expand-env=true"
    extraEnvFrom:
    - secretRef:
        name: "minio"
  backend:
    extraArgs:
    - "-config.expand-env=true"
    extraEnvFrom:
    - secretRef:
        name: "minio"
alloy:
  alloy:
    clustering:
      enabled: true
    configMap:
      create: false
      name: "agent-configmap"
      key: 'config.river'
    resources:
      requests:
        cpu: '1000m'
        memory: '600Mi'
      limits:
        memory: '4Gi'
    extraPorts:
    - name: "otel"
      port: 4317
      targetPort: 4317
      protocol: "TCP"
    - name: "thrifthttp"
      port: 14268
      targetPort: 14268
      protocol: "TCP"
  controller:
    type: "statefulset"
    autoscaling:
      enabled: true
      minReplicas: 3
      maxReplicas: 30
      targetMemoryUtilizationPercentage: 90
      targetCPUUtilizationPercentage: 90
mimir-distributed:
  minio:
    enabled: false
  global:
    extraEnvFrom:
    - secretRef:
        name: "minio"
  mimir:
    structuredConfig:
      alertmanager_storage:
        s3:
          bucket_name: mimir-ruler
      blocks_storage:
        backend: s3
        s3:
          bucket_name: mimir-tsdb
      ruler_storage:
        s3:
          bucket_name: mimir-ruler
      common:
        storage:
          backend: s3
          s3:
            bucket_name: mimir-ruler
            access_key_id: "${rootUser}"
            endpoint: "{{ .Release.Name }}-minio.{{ .Release.Namespace }}.svc:9000"
            secret_access_key: "${rootPassword}"
            insecure: true
      limits:
        compactor_blocks_retention_period: 30d
tempo-distributed:
  tempo:
    structuredConfig:
      storage:
        trace:
          backend: s3
          s3:
            bucket: tempo
            endpoint: "{{ .Release.Name }}-minio.{{ .Release.Namespace }}.svc:9000"
            access_key: "${rootUser}"
            secret_key: "${rootPassword}"
            insecure: true
  distributor:
    extraArgs:
    - "-config.expand-env=true"
    extraEnvFrom:
    - secretRef:
        name: "minio"
  ingester:
    extraArgs:
    - "-config.expand-env=true"
    extraEnvFrom:
    - secretRef:
        name: "minio"
  compactor:
    extraArgs:
    - "-config.expand-env=true"
    extraEnvFrom:
    - secretRef:
        name: "minio"
  querier:
    extraArgs:
    - "-config.expand-env=true"
    extraEnvFrom:
    - secretRef:
        name: "minio"
  queryFrontend:
    extraArgs:
    - "-config.expand-env=true"
    extraEnvFrom:
    - secretRef:
        name: "minio"
  traces:
    otlp:
      http:
        enabled: true
      grpc:
        enabled: true
minio:
  existingSecret: "minio"
  buckets:
    - name: loki-chunks
      policy: none
      purge: false
    - name: loki-ruler
      policy: none
      purge: false
    - name: tempo
      policy: none
      purge: false
    - name: mimir-ruler
      policy: none
      purge: false
    - name: mimir-tsdb
      policy: none
      purge: false
  mode: standalone
  persistence:
    size: 5Gi
  resources:
    requests:
      cpu: 100m
      memory: 128Mi
  # Changed the mc config path to '/tmp' from '/etc' as '/etc' is only writable by root and OpenShift will not permit this.
  configPathmc: "/tmp/minio/mc/"